<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="分布式系统架构——Hadoop MapReduce全方位描述"><meta name="keywords" content="翻译,mapreduce"><meta name="author" content="AlexanderKwong"><meta name="copyright" content="AlexanderKwong"><title>分布式系统架构——Hadoop MapReduce全方位描述 | AlexanderKwong</title><link rel="shortcut icon" href="/melody-favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.6.1"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.6.1"><link rel="dns-prefetch" href="https://cdn.staticfile.org"><link rel="dns-prefetch" href="https://cdn.bootcss.com"><link rel="dns-prefetch" href="https://creativecommons.org"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  }
} </script></head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar"><div class="toggle-sidebar-info text-center"><span data-toggle="Toggle article">Toggle site</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="/img/avatar.png"></div><div class="author-info__name text-center">AlexanderKwong</div><div class="author-info__description text-center"></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">2</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">Tags</span><span class="pull-right">3</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">Categories</span><span class="pull-right">2</span></a></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(https://api.neweb.top/bing.php)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">AlexanderKwong</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus"><a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a></span></div><div id="post-info"><div id="post-title">分布式系统架构——Hadoop MapReduce全方位描述</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2019-10-19</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/hadoop/">hadoop</a></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><p>#Hadoop MapReduce全方位描述</p>
<p>MapReduce是目前分布式计算中相当流行的一个框架。第一次描述这个原理的是Google在2004年发表的一篇<a href="http://static.googleusercontent.com/media/research.google.com/en//archive/mapreduce-osdi04.pdf" target="_blank" rel="noopener">论文</a>。当下Map Reduce是每个人都知道每个人都在说的一个名词，因为它作为Hadoop项目的基础之一。对于大部分人来说，Map Reduce等价于“Hadoop”和“Big Data”，这完全是错误的。但有一些人仅通过WordCount理解了最简单的情况，也许还能使用Map Reduce构建一个反向索引。</p>
<p>但作为一个简单的概念，却在Hadoop中有着一中复杂的实现。我曾经尝试在全网中去找一个关于MR的有好的图表的全方位的描述，但我失败了。所有的图都重复着“Map-Sort-Combine-Shuffle-Reduce”。当然了，能理解框架这样的工作原理是好的，但，这个框架大量的可调参数那又如何？如果你减少或者增加Map输出缓冲区大小会发生什么？这些图对于此毫无帮助。这就是我要基于最新可用的Hadoop库的源代码，自己画图和自己描述一遍的原因。</p>
<img src="/2019/10/19/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E2%80%94%E2%80%94Hadoop-MapReduce%E5%85%A8%E6%96%B9%E4%BD%8D%E6%8F%8F%E8%BF%B0/mapreduce%E6%B5%81%E7%A8%8B.png" class="" title="Hadoop MapReduce Comprehensive Diagram">

<p>整个MapReduce由InputFormat开始。它是你在驱动（driver）程序中指定的类，它了解输入并提供给你两个主要的接口方法：getSplit返回输入数据分片的集合，getRecordReader提供一个iterable接口来从一个输入分片中读取所有的记录。输入分片的大小取决于InputFormat——对于文本文件，它就是HDFS（<code>dfs.blocksize</code>）中的一个块；对于gzip压缩文件，它就是整个文件（由于gzip包是不可分的），等等。每一个Mapper处理一个单独的输入分片，就是说大部分情况下它处理<code>dfs.blocksize</code>的数据，默认等于128MB。</p>
<p>对输入的每一个键值对，基本上就是说在InputFormat中定义的RecordReader所返回的每个键值对，你的Mapper类中的map方法都被执行一次。对于它们中的每一个，你产生一些输出，并写进map方法中的一个参数——Context对象中。</p>
<p>负责收集map的输出的类是由属性<code>mapreduce.job.map.outout.collector.class</code>指定，默认实现是<code>org.apache.hadoop.mapred.MapTsk$MapOutputBuffer</code>。接下来的步骤我将讲解，当没有别的实现被Hadoop装载时，这个默认的实现。</p>
<p>“Map”方法的输出首先进入Partitioner类中的getPartition方法中。它接收参数为key，value，reducer的数目（partition的数目），返回这个键值对应该前往的partition的序号。默认实现如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HashPartitioner</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; <span class="keyword">extends</span> <span class="title">Partitioner</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; </span>&#123;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getPartition</span><span class="params">(K key, V value, <span class="keyword">int</span> numReduceTasks)</span> </span>&#123;</span><br><span class="line">		<span class="keyword">return</span> (key.hashCode() &amp; Integer.MAX_VALUE) % numReduceTasks;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>然后，连同partition序号的输出被写入内存中的环形缓冲区，它的大小由参数<code>mapreduce.task.io.sort.mb</code>（默认100MB）来定义——这是允许map输出占据的总的内存大小。如果你不匹配得下这个大小，你的数据将溢写到硬盘。注意了，由于<code>dfs.blocksize</code>默认值由64MB变为128MB，即使最简单的恒等式mapper将会溢写磁盘，因为map默认的输出缓冲区小于输入分片的大小。</p>
<p>溢写是在一个单独的线程中被执行。它在环形缓冲区被填充至参数<code>mapreduce.map.sort.spill.percent</code>指定的百分比（默认0.8，默认的冲去都大小是80MB）时被启动。默认地，如果单个输入分片的map任务输出大于80MB的数据，这数据会被溢写到本地磁盘。在一个单独的线程中进行溢写使得mapper在溢写数据时能继续调用函数处理输入数据。Mapper函数仅在mapper处理速率大于溢写速率时被停止执行，这种情况下内存缓冲区100%耗尽，mapper函数将堵塞并等待溢写线程清空出一些空间。</p>
<p>溢写线程会写入数据到调用mapper函数的服务器的本地文件。决定哪个目录是由<code>mapreduce.job.local.dir</code>参数设置的，包含了一系列被MR jobs在集群中用于存临时数据的目录。以轮询机制从这些目录中被选出一个。但数据不仅仅被写进磁盘。在这之前会执行排序，使用的是快速排序算法。Comparator函数以首先比较partition序号之后是键值 这样的方式被定义，这种方式下，数据按partition排序，在partition内按key排序。</p>
<p>在排序步骤之后的是Combiner调用。它是用来减少写进磁盘的数据量的。有一种极端情况下sorter和combiner都不会被调用——mapper产生的单条记录太大放不进内存（大于输出缓冲区的容量）。这种情况下，这条记录将直接写进磁盘，而不经过combiner和sorter。Combiner函数的输出会被写进磁盘。</p>
<p>当mapper调用“Spill”方法完成 ，不管mapper输出了多少的数据，就是说，数据被写进磁盘至少一次。这将执行相同的任务——排序（sort）和合并（combine）数据，然后输出到文件。</p>
<p>每个被溢写线程输出的文件都有一个索引，索引包含每个文件中partition开始位置和结束位置两个信息。这些索引在内存中被排好序，这项任务所分配的内存由参数<code>mapreduce.task.index.cache.limit.bytes</code>来指定，默认等于1MB。如果内存不足以存储这些索引，那么接下来创建的索引将一同写进磁盘中的溢写文件。</p>
<p>当mapper和最后一个溢写任务完成，溢写线程被终止了，开始merge阶段。在merge阶段中，所有的溢写文件应该一起被分组，组成单个的map输出文件。默认一个单独的merge进程能处理达100个的溢写文件（负责这个的参数是：<code>mapreduce.task.io.sort.factor</code>）。如果溢写的数量大于这个值，后来被执行的merges会将其分别合并为单个文件。</p>
<p>merge阶段中，如果文件数量大于等于<code>min.num.spills.for.combine</code>（默认是3），在写进磁盘钱combiner会在merge的结果之上被执行。</p>
<p>MapTask的结果是单个文件，包含着mapper的所有输出以及描述partitions起止信息的索引，索引中的信息使得ReduceTask能够为reducer轻松抓取相关部分来处理。</p>
<p>现在让我们来描述一下ReduceTask。Reducer的数量由参数<code>mapreduce.job.reduces</code>来指定，默认1，这跟mapper有所区别。所有关于reduce之前执行的shuffle以及merge的逻辑，都由一个“Shuffle Consumer Plugin”的实现类来定义，这个类事由参数<code>mapreduce.job.reduce.shuffle.consumer.plugin.class</code>的值来决定，默认是<code>org.apache.hadoop.mapreduce.task.reduce.Shuffle</code>。这是Hadoop所装载的唯一实现，所以之后的描述只论述它。</p>
<p>Reduce端做的第一件事就是开启“Event Fetcher”线程，它将轮询application master来监听mapper状态以及等待mapper执行结束事件。当它完成了，信息会传递给其中一中“Fetcher”线程。“Fetcher”线程的数量由参数<code>mapred.reduce.parallel.copies</code>来定义，默认是5，意味着单个reduce任务有5个线程来并行地从多个mapper复制数据。执行fetch使用HTTP或HTTPS协议让fecher连接相应datanode的URL。</p>
<p>Fetcher从Mapper端下载到的所有数据被存在内存中。为此分配的内存等价于由参数<code>mapreduce.reduce.shuffle.input.buffer.percent</code>指定的占据reducer内存的百分比，而reducer内存由<code>mapreduce.reduce.memory.totalbytes</code>决定。这两个值默认分别是0.7和1024MB，默认单个reducer能够保存于内存额map输出的总量为716MB。如果这点内存不够，fetcher开始将map的输出保存到reducer端的本地磁盘，由<code>mapreduce.job.local.dir</code>指定的一个目录。<br>紧接着fetchers的是Mergers。但它们不会等到所有的fetch进程处理完，它们是在一个独立线程中运行。在Hadoop中有3种merger实现，每一种都是在一个独立线程中工作：</p>
<ol>
<li><code>InMemory merger</code>。不能被禁止，当内存缓冲区被当前任务fetch到的MapTask输出达到<code>reduce.shuffle.merge.percent</code>指定占据这个缓冲区的总内存的百分比时 被触发。在merge之后执行combiner。输出被写进磁盘。总要被执行一次以上。</li>
<li><code>MemToMem merger</code>。可以通过设置<code>reduce.merge.memtomem.enabled</code>启用（默认禁用）。它在内存中合并mapper输出并将结果回写到内存中。当MapTask输出量确切地达到<code>mapreduce.redice.merge.memtomen.threshold</code>时被触发，默认等价于1000。</li>
<li><code>OnDisk merger</code>。在磁盘中合并文件，当文件数量增加至（2 * <code>task.io.sort.factor</code> -1）时触发，但单次执行不会合并超过<code>mapreduce.task.io.sort.factor</code>个文件。</li>
</ol>
<p>所有的这些mergers接下来是第四个叫做finalMerge的。这个merge在reducer的主线程中执行，单次运行来合并 所有内存中剩下的MapTask输出 和 所有由InMemory或OnDisk mergers创建的文件。Final merge的输出被分片存于RAM和磁盘。被用作reducer输入的RAM总量由<code>mapred.job.reduce.markreset.buffer.percent</code>所指定的reducer内存总量的百分比，目前默认是0。</p>
<p>这些准备工作之后reducer启动了，他的输出直接写进HDFS。</p>
<p>这就是全部的描述。</p>
<p>原文链接：<a href="https://0x0fff.com/hadoop-mapreduce-comprehensive-description/" target="_blank" rel="noopener">https://0x0fff.com/hadoop-mapreduce-comprehensive-description/</a></p>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined" target="_blank" rel="noopener">AlexanderKwong</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="https://alexanderkwong.github.io/2019/10/19/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E2%80%94%E2%80%94Hadoop-MapReduce%E5%85%A8%E6%96%B9%E4%BD%8D%E6%8F%8F%E8%BF%B0/">https://alexanderkwong.github.io/2019/10/19/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E2%80%94%E2%80%94Hadoop-MapReduce%E5%85%A8%E6%96%B9%E4%BD%8D%E6%8F%8F%E8%BF%B0/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E7%BF%BB%E8%AF%91/">翻译</a><a class="post-meta__tags" href="/tags/mapreduce/">mapreduce</a></div><nav id="pagination"><div class="prev-post pull-left"><a href="/2019/10/22/Spark%E6%9E%B6%E6%9E%84-Shuffle/"><i class="fa fa-chevron-left">  </i><span>Spark架构:Shuffle</span></a></div></nav></div></div><footer class="footer-bg" style="background-image: url(https://api.neweb.top/bing.php)"><div class="layout" id="footer"><div class="copyright">&copy;2013 - 2019 By AlexanderKwong</div><div class="framework-info"><span>Driven - </span><a href="http://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody" target="_blank" rel="noopener"><span>Melody</span></a></div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file-o"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.6.1"></script><script src="/js/fancybox.js?version=1.6.1"></script><script src="/js/sidebar.js?version=1.6.1"></script><script src="/js/copy.js?version=1.6.1"></script><script src="/js/fireworks.js?version=1.6.1"></script><script src="/js/transition.js?version=1.6.1"></script><script src="/js/scroll.js?version=1.6.1"></script><script src="/js/head.js?version=1.6.1"></script><script>if(/Android|webOS|iPhone|iPod|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
}</script></body></html>